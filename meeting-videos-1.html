<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.4 Meeting Videos | Introduction to Statistical Learning Using R Book Club</title>
  <meta name="description" content="This is the product of the R4DS Online Learning Community’s Introduction to Statistical Learning Using R Book Club." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="2.4 Meeting Videos | Introduction to Statistical Learning Using R Book Club" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the product of the R4DS Online Learning Community’s Introduction to Statistical Learning Using R Book Club." />
  <meta name="github-repo" content="r4ds/bookclub-islr" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.4 Meeting Videos | Introduction to Statistical Learning Using R Book Club" />
  
  <meta name="twitter:description" content="This is the product of the R4DS Online Learning Community’s Introduction to Statistical Learning Using R Book Club." />
  

<meta name="author" content="The R4DS Online Learning Community" />


<meta name="date" content="2022-03-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="exercises.html"/>
<link rel="next" href="linear.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Statistical Learning Using R Book Club</a></li>

<li class="divider"></li>
<li><a href="index.html#welcome">Welcome<span></span></a><ul>
<li><a href="book-club-meetings.html#book-club-meetings">Book club meetings<span></span></a></li>
<li><a href="st-edition-vs-2nd-edition.html#st-edition-vs-2nd-edition">1st edition vs 2nd edition<span></span></a></li>
<li><a href="pace.html#pace">Pace<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction<span></span></a><ul>
<li class="chapter" data-level="1.1" data-path="what-is-statistical-learning.html"><a href="what-is-statistical-learning.html"><i class="fa fa-check"></i><b>1.1</b> What is statistical learning?<span></span></a></li>
<li class="chapter" data-level="1.2" data-path="why-islr.html"><a href="why-islr.html"><i class="fa fa-check"></i><b>1.2</b> Why ISLR?<span></span></a></li>
<li class="chapter" data-level="1.3" data-path="notation.html"><a href="notation.html"><i class="fa fa-check"></i><b>1.3</b> Notation<span></span></a></li>
<li class="chapter" data-level="1.4" data-path="what-have-we-gotten-ourselves-into.html"><a href="what-have-we-gotten-ourselves-into.html"><i class="fa fa-check"></i><b>1.4</b> What have we gotten ourselves into?<span></span></a></li>
<li class="chapter" data-level="1.5" data-path="wheres-the-data.html"><a href="wheres-the-data.html"><i class="fa fa-check"></i><b>1.5</b> Where’s the data?<span></span></a></li>
<li class="chapter" data-level="1.6" data-path="some-useful-resources.html"><a href="some-useful-resources.html"><i class="fa fa-check"></i><b>1.6</b> Some useful resources:<span></span></a></li>
<li class="chapter" data-level="1.7" data-path="what-is-covered-in-the-book.html"><a href="what-is-covered-in-the-book.html"><i class="fa fa-check"></i><b>1.7</b> What is covered in the book?<span></span></a></li>
<li class="chapter" data-level="1.8" data-path="how-is-the-book-divided.html"><a href="how-is-the-book-divided.html"><i class="fa fa-check"></i><b>1.8</b> How is the book divided?<span></span></a></li>
<li class="chapter" data-level="1.9" data-path="some-examples-of-the-problems-addressed-with-statistical-analysis.html"><a href="some-examples-of-the-problems-addressed-with-statistical-analysis.html"><i class="fa fa-check"></i><b>1.9</b> Some examples of the problems addressed with statistical analysis<span></span></a></li>
<li class="chapter" data-level="1.10" data-path="datasets-provided-in-the-islr2-package.html"><a href="datasets-provided-in-the-islr2-package.html"><i class="fa fa-check"></i><b>1.10</b> Datasets provided in the ISLR2 package<span></span></a><ul>
<li class="chapter" data-level="1.10.1" data-path="datasets-provided-in-the-islr2-package.html"><a href="datasets-provided-in-the-islr2-package.html#example-datasets"><i class="fa fa-check"></i><b>1.10.1</b> Example datasets<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="meeting-videos.html"><a href="meeting-videos.html"><i class="fa fa-check"></i><b>1.11</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="1.11.1" data-path="meeting-videos.html"><a href="meeting-videos.html#cohort-1"><i class="fa fa-check"></i><b>1.11.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="1.11.2" data-path="meeting-videos.html"><a href="meeting-videos.html#cohort-2"><i class="fa fa-check"></i><b>1.11.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="1.11.3" data-path="meeting-videos.html"><a href="meeting-videos.html#cohort-3"><i class="fa fa-check"></i><b>1.11.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="learning.html"><a href="learning.html"><i class="fa fa-check"></i><b>2</b> Statistical Learning<span></span></a><ul>
<li class="chapter" data-level="2.1" data-path="what-is-statistical-learning-1.html"><a href="what-is-statistical-learning-1.html"><i class="fa fa-check"></i><b>2.1</b> What is Statistical Learning?<span></span></a><ul>
<li class="chapter" data-level="2.1.1" data-path="what-is-statistical-learning-1.html"><a href="what-is-statistical-learning-1.html#why-estimate-f"><i class="fa fa-check"></i><b>2.1.1</b> Why Estimate <span class="math inline">\(f\)</span>?<span></span></a></li>
<li class="chapter" data-level="2.1.2" data-path="what-is-statistical-learning-1.html"><a href="what-is-statistical-learning-1.html#how-do-we-estimate-f"><i class="fa fa-check"></i><b>2.1.2</b> How do we estimate <span class="math inline">\(f\)</span>?<span></span></a></li>
<li class="chapter" data-level="2.1.3" data-path="what-is-statistical-learning-1.html"><a href="what-is-statistical-learning-1.html#prediction-accuracy-vs-model-interpretability"><i class="fa fa-check"></i><b>2.1.3</b> Prediction Accuracy vs Model Interpretability<span></span></a></li>
<li class="chapter" data-level="2.1.4" data-path="what-is-statistical-learning-1.html"><a href="what-is-statistical-learning-1.html#supervised-versus-unsupervised-learning"><i class="fa fa-check"></i><b>2.1.4</b> Supervised Versus Unsupervised Learning<span></span></a></li>
<li class="chapter" data-level="2.1.5" data-path="what-is-statistical-learning-1.html"><a href="what-is-statistical-learning-1.html#regression-versus-classification-problems"><i class="fa fa-check"></i><b>2.1.5</b> Regression Versus Classification Problems<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html"><i class="fa fa-check"></i><b>2.2</b> Assessing Model Accuracy<span></span></a><ul>
<li class="chapter" data-level="2.2.1" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#measuring-quality-of-fit"><i class="fa fa-check"></i><b>2.2.1</b> Measuring Quality of Fit<span></span></a></li>
<li class="chapter" data-level="2.2.2" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-bias-variance-trade-off"><i class="fa fa-check"></i><b>2.2.2</b> The Bias-Variance Trade-Off<span></span></a></li>
<li class="chapter" data-level="2.2.3" data-path="assessing-model-accuracy.html"><a href="assessing-model-accuracy.html#the-classification-setting"><i class="fa fa-check"></i><b>2.2.3</b> The Classification Setting<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>2.3</b> Exercises<span></span></a></li>
<li class="chapter" data-level="2.4" data-path="meeting-videos-1.html"><a href="meeting-videos-1.html"><i class="fa fa-check"></i><b>2.4</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="2.4.1" data-path="meeting-videos-1.html"><a href="meeting-videos-1.html#cohort-1-1"><i class="fa fa-check"></i><b>2.4.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="2.4.2" data-path="meeting-videos-1.html"><a href="meeting-videos-1.html#cohort-2-1"><i class="fa fa-check"></i><b>2.4.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="2.4.3" data-path="meeting-videos-1.html"><a href="meeting-videos-1.html#cohort-3-1"><i class="fa fa-check"></i><b>2.4.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear.html"><a href="linear.html"><i class="fa fa-check"></i><b>3</b> Linear Regression<span></span></a><ul>
<li class="chapter" data-level="3.1" data-path="questions-to-answer.html"><a href="questions-to-answer.html"><i class="fa fa-check"></i><b>3.1</b> Questions to Answer<span></span></a></li>
<li class="chapter" data-level="3.2" data-path="simple-linear-regression-definition.html"><a href="simple-linear-regression-definition.html"><i class="fa fa-check"></i><b>3.2</b> Simple Linear Regression: Definition<span></span></a></li>
<li class="chapter" data-level="3.3" data-path="simple-linear-regression-visualization.html"><a href="simple-linear-regression-visualization.html"><i class="fa fa-check"></i><b>3.3</b> Simple Linear Regression: Visualization<span></span></a></li>
<li class="chapter" data-level="3.4" data-path="simple-linear-regression-math.html"><a href="simple-linear-regression-math.html"><i class="fa fa-check"></i><b>3.4</b> Simple Linear Regression: Math<span></span></a><ul>
<li class="chapter" data-level="3.4.1" data-path="simple-linear-regression-math.html"><a href="simple-linear-regression-math.html#visualization-of-fit"><i class="fa fa-check"></i><b>3.4.1</b> Visualization of Fit<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="assessing-accuracy-of-coefficient-estimates.html"><a href="assessing-accuracy-of-coefficient-estimates.html"><i class="fa fa-check"></i><b>3.5</b> Assessing Accuracy of Coefficient Estimates<span></span></a></li>
<li class="chapter" data-level="3.6" data-path="meeting-videos-2.html"><a href="meeting-videos-2.html"><i class="fa fa-check"></i><b>3.6</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="3.6.1" data-path="meeting-videos-2.html"><a href="meeting-videos-2.html#cohort-1-2"><i class="fa fa-check"></i><b>3.6.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="3.6.2" data-path="meeting-videos-2.html"><a href="meeting-videos-2.html#cohort-2-2"><i class="fa fa-check"></i><b>3.6.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="3.6.3" data-path="meeting-videos-2.html"><a href="meeting-videos-2.html#cohort-3-2"><i class="fa fa-check"></i><b>3.6.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>4</b> Classification<span></span></a><ul>
<li class="chapter" data-level="4.1" data-path="an-overview-of-classification.html"><a href="an-overview-of-classification.html"><i class="fa fa-check"></i><b>4.1</b> An Overview of Classification<span></span></a></li>
<li class="chapter" data-level="4.2" data-path="why-not-linear-regression.html"><a href="why-not-linear-regression.html"><i class="fa fa-check"></i><b>4.2</b> Why NOT Linear Regression?<span></span></a></li>
<li class="chapter" data-level="4.3" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>4.3</b> Logistic Regression<span></span></a><ul>
<li class="chapter" data-level="4.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>4.3.1</b> Multiple Logistic Regression<span></span></a></li>
<li class="chapter" data-level="4.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>4.3.2</b> Multinomial Logistic Regression<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="generative-models-for-classification.html"><a href="generative-models-for-classification.html"><i class="fa fa-check"></i><b>4.4</b> Generative Models for Classification<span></span></a></li>
<li class="chapter" data-level="4.5" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html"><i class="fa fa-check"></i><b>4.5</b> A Comparison of Classification Methods<span></span></a><ul>
<li class="chapter" data-level="4.5.1" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#linear-discriminant-analysis-for-p-1"><i class="fa fa-check"></i><b>4.5.1</b> Linear Discriminant Analysis for p = 1<span></span></a></li>
<li class="chapter" data-level="4.5.2" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#linear-discriminant-analysis-for-p-1-1"><i class="fa fa-check"></i><b>4.5.2</b> Linear Discriminant Analysis for p &gt; 1<span></span></a></li>
<li class="chapter" data-level="4.5.3" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#quadratic-discriminant-analysis-qda"><i class="fa fa-check"></i><b>4.5.3</b> Quadratic Discriminant Analysis (QDA)<span></span></a></li>
<li class="chapter" data-level="4.5.4" data-path="a-comparison-of-classification-methods.html"><a href="a-comparison-of-classification-methods.html#naive-bayes"><i class="fa fa-check"></i><b>4.5.4</b> Naive Bayes<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="summary-of-the-classification-methods.html"><a href="summary-of-the-classification-methods.html"><i class="fa fa-check"></i><b>4.6</b> Summary of the classification methods<span></span></a><ul>
<li class="chapter" data-level="4.6.1" data-path="summary-of-the-classification-methods.html"><a href="summary-of-the-classification-methods.html#an-analytical-comparison"><i class="fa fa-check"></i><b>4.6.1</b> An Analytical Comparison<span></span></a></li>
<li class="chapter" data-level="4.6.2" data-path="summary-of-the-classification-methods.html"><a href="summary-of-the-classification-methods.html#an-empirical-comparison"><i class="fa fa-check"></i><b>4.6.2</b> An Empirical Comparison<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>4.7</b> Generalized Linear Models<span></span></a></li>
<li class="chapter" data-level="4.8" data-path="linear-regression-with-count-data---negative-values.html"><a href="linear-regression-with-count-data---negative-values.html"><i class="fa fa-check"></i><b>4.8</b> Linear regression with count data - negative values<span></span></a></li>
<li class="chapter" data-level="4.9" data-path="linear-regression-with-count-data---heteroscedasticity.html"><a href="linear-regression-with-count-data---heteroscedasticity.html"><i class="fa fa-check"></i><b>4.9</b> Linear regression with count data - heteroscedasticity<span></span></a></li>
<li class="chapter" data-level="4.10" data-path="problems-with-linear-regression-of-count-data.html"><a href="problems-with-linear-regression-of-count-data.html"><i class="fa fa-check"></i><b>4.10</b> Problems with linear regression of count data<span></span></a></li>
<li class="chapter" data-level="4.11" data-path="poisson-distribution.html"><a href="poisson-distribution.html"><i class="fa fa-check"></i><b>4.11</b> Poisson distribution<span></span></a></li>
<li class="chapter" data-level="4.12" data-path="poisson-regression-model-mean-lambda.html"><a href="poisson-regression-model-mean-lambda.html"><i class="fa fa-check"></i><b>4.12</b> Poisson Regression Model mean (lambda)<span></span></a></li>
<li class="chapter" data-level="4.13" data-path="estimating-the-poisson-regression-parameters.html"><a href="estimating-the-poisson-regression-parameters.html"><i class="fa fa-check"></i><b>4.13</b> Estimating the Poisson Regression parameters<span></span></a></li>
<li class="chapter" data-level="4.14" data-path="interpreting-poisson-regression.html"><a href="interpreting-poisson-regression.html"><i class="fa fa-check"></i><b>4.14</b> Interpreting Poisson Regression<span></span></a></li>
<li class="chapter" data-level="4.15" data-path="advantages-of-poisson-regression.html"><a href="advantages-of-poisson-regression.html"><i class="fa fa-check"></i><b>4.15</b> Advantages of Poisson Regression<span></span></a></li>
<li class="chapter" data-level="4.16" data-path="generalized-linear-models-1.html"><a href="generalized-linear-models-1.html"><i class="fa fa-check"></i><b>4.16</b> Generalized Linear Models<span></span></a></li>
<li class="chapter" data-level="4.17" data-path="addendum---logistic-regression-assumptions.html"><a href="addendum---logistic-regression-assumptions.html"><i class="fa fa-check"></i><b>4.17</b> Addendum - Logistic Regression Assumptions<span></span></a></li>
<li class="chapter" data-level="4.18" data-path="lab-classification-methods.html"><a href="lab-classification-methods.html"><i class="fa fa-check"></i><b>4.18</b> Lab: Classification Methods<span></span></a></li>
<li class="chapter" data-level="4.19" data-path="meeting-videos-3.html"><a href="meeting-videos-3.html"><i class="fa fa-check"></i><b>4.19</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="4.19.1" data-path="meeting-videos-3.html"><a href="meeting-videos-3.html#cohort-1-3"><i class="fa fa-check"></i><b>4.19.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="4.19.2" data-path="meeting-videos-3.html"><a href="meeting-videos-3.html#cohort-2-3"><i class="fa fa-check"></i><b>4.19.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="4.19.3" data-path="meeting-videos-3.html"><a href="meeting-videos-3.html#cohort-3-3"><i class="fa fa-check"></i><b>4.19.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="resampling-methods.html"><a href="resampling-methods.html"><i class="fa fa-check"></i><b>5</b> Resampling Methods<span></span></a><ul>
<li class="chapter" data-level="5.1" data-path="validation-set-approach.html"><a href="validation-set-approach.html"><i class="fa fa-check"></i><b>5.1</b> Validation Set Approach<span></span></a></li>
<li class="chapter" data-level="5.2" data-path="validation-error-rate-varies-depending-on-data-set.html"><a href="validation-error-rate-varies-depending-on-data-set.html"><i class="fa fa-check"></i><b>5.2</b> Validation Error Rate Varies Depending on Data Set<span></span></a></li>
<li class="chapter" data-level="5.3" data-path="leave-one-out-cross-validation-loocv.html"><a href="leave-one-out-cross-validation-loocv.html"><i class="fa fa-check"></i><b>5.3</b> Leave-One-Out Cross-Validation (LOOCV)<span></span></a></li>
<li class="chapter" data-level="5.4" data-path="advantages-of-loocv-over-validation-set-approach.html"><a href="advantages-of-loocv-over-validation-set-approach.html"><i class="fa fa-check"></i><b>5.4</b> Advantages of LOOCV over Validation Set Approach<span></span></a></li>
<li class="chapter" data-level="5.5" data-path="k-fold-cross-validation.html"><a href="k-fold-cross-validation.html"><i class="fa fa-check"></i><b>5.5</b> k-fold Cross-Validation<span></span></a></li>
<li class="chapter" data-level="5.6" data-path="graphical-illustration-of-k-fold-approach.html"><a href="graphical-illustration-of-k-fold-approach.html"><i class="fa fa-check"></i><b>5.6</b> Graphical Illustration of k-fold Approach<span></span></a></li>
<li class="chapter" data-level="5.7" data-path="advantages-of-k-fold-cross-validation-over-loocv.html"><a href="advantages-of-k-fold-cross-validation-over-loocv.html"><i class="fa fa-check"></i><b>5.7</b> Advantages of k-fold Cross-Validation over LOOCV<span></span></a></li>
<li class="chapter" data-level="5.8" data-path="bias-variance-tradeoff-and-k-fold-cross-validation.html"><a href="bias-variance-tradeoff-and-k-fold-cross-validation.html"><i class="fa fa-check"></i><b>5.8</b> Bias-Variance Tradeoff and k-fold Cross-Validation<span></span></a></li>
<li class="chapter" data-level="5.9" data-path="cross-validation-on-classification-problems.html"><a href="cross-validation-on-classification-problems.html"><i class="fa fa-check"></i><b>5.9</b> Cross-Validation on Classification Problems<span></span></a></li>
<li class="chapter" data-level="5.10" data-path="logistic-polynomial-regression-bayes-decision-boundaries-and-k-fold-cross-validation.html"><a href="logistic-polynomial-regression-bayes-decision-boundaries-and-k-fold-cross-validation.html"><i class="fa fa-check"></i><b>5.10</b> Logistic Polynomial Regression, Bayes Decision Boundaries, and k-fold Cross Validation<span></span></a></li>
<li class="chapter" data-level="5.11" data-path="the-bootstrap.html"><a href="the-bootstrap.html"><i class="fa fa-check"></i><b>5.11</b> The Bootstrap<span></span></a></li>
<li class="chapter" data-level="5.12" data-path="population-distribution-compared-to-bootstrap-distribution.html"><a href="population-distribution-compared-to-bootstrap-distribution.html"><i class="fa fa-check"></i><b>5.12</b> Population Distribution Compared to Bootstrap Distribution<span></span></a></li>
<li class="chapter" data-level="5.13" data-path="bootstrap-standard-error.html"><a href="bootstrap-standard-error.html"><i class="fa fa-check"></i><b>5.13</b> Bootstrap Standard Error<span></span></a></li>
<li class="chapter" data-level="5.14" data-path="lab-cross-validation-and-the-bootstrap.html"><a href="lab-cross-validation-and-the-bootstrap.html"><i class="fa fa-check"></i><b>5.14</b> Lab: Cross-Validation and the Bootstrap<span></span></a><ul>
<li class="chapter" data-level="5.14.1" data-path="lab-cross-validation-and-the-bootstrap.html"><a href="lab-cross-validation-and-the-bootstrap.html#the-validation-set-approach"><i class="fa fa-check"></i><b>5.14.1</b> The Validation Set Approach<span></span></a></li>
<li class="chapter" data-level="5.14.2" data-path="lab-cross-validation-and-the-bootstrap.html"><a href="lab-cross-validation-and-the-bootstrap.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>5.14.2</b> Leave-One-Out Cross-Validation<span></span></a></li>
<li class="chapter" data-level="5.14.3" data-path="lab-cross-validation-and-the-bootstrap.html"><a href="lab-cross-validation-and-the-bootstrap.html#k-fold-cross-validation-1"><i class="fa fa-check"></i><b>5.14.3</b> k-Fold Cross-Validation<span></span></a></li>
<li class="chapter" data-level="5.14.4" data-path="lab-cross-validation-and-the-bootstrap.html"><a href="lab-cross-validation-and-the-bootstrap.html#the-bootstrap-1"><i class="fa fa-check"></i><b>5.14.4</b> The Bootstrap<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.15" data-path="meeting-videos-4.html"><a href="meeting-videos-4.html"><i class="fa fa-check"></i><b>5.15</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="5.15.1" data-path="meeting-videos-4.html"><a href="meeting-videos-4.html#cohort-1-4"><i class="fa fa-check"></i><b>5.15.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="5.15.2" data-path="meeting-videos-4.html"><a href="meeting-videos-4.html#cohort-2-4"><i class="fa fa-check"></i><b>5.15.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="5.15.3" data-path="meeting-videos-4.html"><a href="meeting-videos-4.html#cohort-3-4"><i class="fa fa-check"></i><b>5.15.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html"><i class="fa fa-check"></i><b>6</b> Linear Model Selection and Regularization<span></span></a><ul>
<li class="chapter" data-level="6.1" data-path="subset-selection.html"><a href="subset-selection.html"><i class="fa fa-check"></i><b>6.1</b> Subset Selection<span></span></a></li>
<li><a href="context-for-this-chapter.html#context-for-this-chapter">Context for This Chapter<span></span></a></li>
<li><a href="best-subset-selection-bss.html#best-subset-selection-bss">Best Subset Selection (BSS)<span></span></a></li>
<li><a href="bss-algorithm.html#bss-algorithm">BSS Algorithm<span></span></a></li>
<li><a href="bss-algorithm-1.html#bss-algorithm-1">BSS Algorithm<span></span></a></li>
<li><a href="behind-the-dots-bssing-islr2credit.html#behind-the-dots-bssing-islr2credit">Behind the dots, BSS’ing ISLR2::Credit<span></span></a></li>
<li><a href="best-subset-selection-bss-1.html#best-subset-selection-bss-1">Best Subset Selection (BSS)<span></span></a></li>
<li><a href="forward-stepwise-subset-selection-fsss.html#forward-stepwise-subset-selection-fsss">Forward Stepwise Subset Selection (FsSS)<span></span></a></li>
<li><a href="fsssing-islr2credit.html#fsssing-islr2credit">FsSS’ing ISLR2::Credit<span></span></a></li>
<li><a href="backward-stepwise-subset-selection-bsss.html#backward-stepwise-subset-selection-bsss">Backward Stepwise Subset Selection (BsSS)<span></span></a></li>
<li><a href="guided-searches.html#guided-searches">“Guided” searches<span></span></a></li>
<li><a href="choosing-the-best-model.html#choosing-the-best-model">Choosing the best model<span></span></a></li>
<li><a href="adjustment-methods.html#adjustment-methods">Adjustment Methods<span></span></a></li>
<li><a href="avoiding-adjustment-methods.html#avoiding-adjustment-methods">Avoiding Adjustment Methods<span></span></a></li>
<li><a href="various-variable-selection-methods-on-islr2credit.html#various-variable-selection-methods-on-islr2credit">Various variable selection methods on ISLR2::Credit<span></span></a></li>
<li><a href="in-conclusion.html#in-conclusion">In conclusion…<span></span></a></li>
<li class="chapter" data-level="6.2" data-path="shrinkage-methods.html"><a href="shrinkage-methods.html"><i class="fa fa-check"></i><b>6.2</b> Shrinkage Methods<span></span></a></li>
<li><a href="overview.html#overview">Overview<span></span></a></li>
<li><a href="ols-review.html#ols-review">OLS review<span></span></a></li>
<li><a href="ridge-regression.html#ridge-regression">Ridge Regression<span></span></a></li>
<li><a href="ridge-regression-visually.html#ridge-regression-visually">Ridge Regression, Visually<span></span></a></li>
<li><a href="ridge-good.html#ridge-good">Ridge, good?<span></span></a></li>
<li><a href="preprocessing.html#preprocessing">Preprocessing<span></span></a></li>
<li><a href="the-lasso.html#the-lasso">The Lasso<span></span></a></li>
<li><a href="justin-grimmer-homework.html#justin-grimmer-homework">Justin Grimmer Homework<span></span></a></li>
<li><a href="visualization-of-such-that-formulations.html#visualization-of-such-that-formulations">Visualization of “such that” formulations<span></span></a></li>
<li><a href="bayesian-interpretation.html#bayesian-interpretation">Bayesian Interpretation<span></span></a></li>
<li><a href="bayesian-interpretation-cont.html#bayesian-interpretation-cont">Bayesian Interpretation (cont)<span></span></a></li>
<li><a href="choosing-the-tuning-parameter.html#choosing-the-tuning-parameter">Choosing the tuning parameter<span></span></a></li>
<li><a href="tuning-lambda.html#tuning-lambda">Tuning <span class="math inline">\(\lambda\)</span><span></span></a></li>
<li class="chapter" data-level="6.3" data-path="dimension-reduction-methods.html"><a href="dimension-reduction-methods.html"><i class="fa fa-check"></i><b>6.3</b> Dimension Reduction Methods<span></span></a></li>
<li><a href="the-math.html#the-math">The Math<span></span></a></li>
<li><a href="principal-components-regression.html#principal-components-regression">Principal Components Regression<span></span></a></li>
<li><a href="principal-components-regression-1.html#principal-components-regression-1">Principal Components Regression<span></span></a></li>
<li><a href="principal-components-regression-2.html#principal-components-regression-2">Principal Components Regression<span></span></a></li>
<li><a href="principal-components-regression-3.html#principal-components-regression-3">Principal Components Regression<span></span></a></li>
<li><a href="principal-components-regression-4.html#principal-components-regression-4">Principal Components Regression<span></span></a></li>
<li><a href="principal-components-regression-5.html#principal-components-regression-5">Principal Components Regression<span></span></a></li>
<li><a href="partial-least-squares.html#partial-least-squares">Partial Least Squares<span></span></a></li>
<li class="chapter" data-level="6.4" data-path="considerations-in-high-dimensions.html"><a href="considerations-in-high-dimensions.html"><i class="fa fa-check"></i><b>6.4</b> Considerations in High Dimensions<span></span></a></li>
<li><a href="considerations-in-high-dimensions-1.html#considerations-in-high-dimensions-1">Considerations in High Dimensions<span></span></a></li>
<li><a href="lasso-etc-vs-dimensionality.html#lasso-etc-vs-dimensionality">Lasso (etc) vs Dimensionality<span></span></a></li>
<li class="chapter" data-level="6.5" data-path="meeting-videos-5.html"><a href="meeting-videos-5.html"><i class="fa fa-check"></i><b>6.5</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="6.5.1" data-path="meeting-videos-5.html"><a href="meeting-videos-5.html#cohort-1-5"><i class="fa fa-check"></i><b>6.5.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="6.5.2" data-path="meeting-videos-5.html"><a href="meeting-videos-5.html#cohort-2-5"><i class="fa fa-check"></i><b>6.5.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="6.5.3" data-path="meeting-videos-5.html"><a href="meeting-videos-5.html#cohort-3-5"><i class="fa fa-check"></i><b>6.5.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html"><i class="fa fa-check"></i><b>7</b> Moving Beyond Linearity<span></span></a><ul>
<li class="chapter" data-level="7.1" data-path="polynomial-and-step-regression.html"><a href="polynomial-and-step-regression.html"><i class="fa fa-check"></i><b>7.1</b> Polynomial and Step Regression<span></span></a></li>
<li class="chapter" data-level="7.2" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>7.2</b> Splines<span></span></a></li>
<li class="chapter" data-level="7.3" data-path="generalized-additive-models.html"><a href="generalized-additive-models.html"><i class="fa fa-check"></i><b>7.3</b> Generalized Additive Models<span></span></a></li>
<li class="chapter" data-level="7.4" data-path="meeting-videos-6.html"><a href="meeting-videos-6.html"><i class="fa fa-check"></i><b>7.4</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="7.4.1" data-path="meeting-videos-6.html"><a href="meeting-videos-6.html#cohort-1-6"><i class="fa fa-check"></i><b>7.4.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="7.4.2" data-path="meeting-videos-6.html"><a href="meeting-videos-6.html#cohort-2-6"><i class="fa fa-check"></i><b>7.4.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="7.4.3" data-path="meeting-videos-6.html"><a href="meeting-videos-6.html#cohort-3-6"><i class="fa fa-check"></i><b>7.4.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="tree-based-methods.html"><a href="tree-based-methods.html"><i class="fa fa-check"></i><b>8</b> Tree-Based Methods<span></span></a><ul>
<li class="chapter" data-level="8.1" data-path="slide-1.html"><a href="slide-1.html"><i class="fa fa-check"></i><b>8.1</b> Slide 1<span></span></a></li>
<li class="chapter" data-level="8.2" data-path="slide-2.html"><a href="slide-2.html"><i class="fa fa-check"></i><b>8.2</b> Slide 2<span></span></a></li>
<li class="chapter" data-level="8.3" data-path="meeting-videos-7.html"><a href="meeting-videos-7.html"><i class="fa fa-check"></i><b>8.3</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="8.3.1" data-path="meeting-videos-7.html"><a href="meeting-videos-7.html#cohort-1-7"><i class="fa fa-check"></i><b>8.3.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="8.3.2" data-path="meeting-videos-7.html"><a href="meeting-videos-7.html#cohort-2-7"><i class="fa fa-check"></i><b>8.3.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="8.3.3" data-path="meeting-videos-7.html"><a href="meeting-videos-7.html#cohort-3-7"><i class="fa fa-check"></i><b>8.3.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>9</b> Support Vector Machines<span></span></a><ul>
<li class="chapter" data-level="9.1" data-path="maximal-margin-classifier-hyperplanes.html"><a href="maximal-margin-classifier-hyperplanes.html"><i class="fa fa-check"></i><b>9.1</b> Maximal Margin Classifier &amp; Hyperplanes<span></span></a></li>
<li class="chapter" data-level="9.2" data-path="using-a-separating-hyperplane-to-classify.html"><a href="using-a-separating-hyperplane-to-classify.html"><i class="fa fa-check"></i><b>9.2</b> Using a Separating Hyperplane to Classify<span></span></a></li>
<li class="chapter" data-level="9.3" data-path="visual-example-of-using-a-hyperplane-to-classify.html"><a href="visual-example-of-using-a-hyperplane-to-classify.html"><i class="fa fa-check"></i><b>9.3</b> Visual Example of Using a Hyperplane to Classify<span></span></a></li>
<li class="chapter" data-level="9.4" data-path="maximal-margin-classifier.html"><a href="maximal-margin-classifier.html"><i class="fa fa-check"></i><b>9.4</b> Maximal Margin Classifier<span></span></a></li>
<li class="chapter" data-level="9.5" data-path="visual-representation-of-maximal-margin-classifier.html"><a href="visual-representation-of-maximal-margin-classifier.html"><i class="fa fa-check"></i><b>9.5</b> Visual Representation of Maximal Margin Classifier<span></span></a></li>
<li class="chapter" data-level="9.6" data-path="mathematics-of-the-mmc.html"><a href="mathematics-of-the-mmc.html"><i class="fa fa-check"></i><b>9.6</b> Mathematics of the MMC<span></span></a></li>
<li class="chapter" data-level="9.7" data-path="support-vector-classifiers.html"><a href="support-vector-classifiers.html"><i class="fa fa-check"></i><b>9.7</b> Support Vector Classifiers<span></span></a></li>
<li class="chapter" data-level="9.8" data-path="mathematics-of-the-svc.html"><a href="mathematics-of-the-svc.html"><i class="fa fa-check"></i><b>9.8</b> Mathematics of the SVC<span></span></a></li>
<li class="chapter" data-level="9.9" data-path="visual-illustration-of-svc.html"><a href="visual-illustration-of-svc.html"><i class="fa fa-check"></i><b>9.9</b> Visual Illustration of SVC<span></span></a></li>
<li class="chapter" data-level="9.10" data-path="support-vector-machines-1.html"><a href="support-vector-machines-1.html"><i class="fa fa-check"></i><b>9.10</b> Support Vector Machines<span></span></a></li>
<li class="chapter" data-level="9.11" data-path="support-vector-machines-cont..html"><a href="support-vector-machines-cont..html"><i class="fa fa-check"></i><b>9.11</b> Support Vector Machines, cont.<span></span></a></li>
<li class="chapter" data-level="9.12" data-path="radial-kernels.html"><a href="radial-kernels.html"><i class="fa fa-check"></i><b>9.12</b> Radial Kernels<span></span></a></li>
<li class="chapter" data-level="9.13" data-path="radial-kernels-cont..html"><a href="radial-kernels-cont..html"><i class="fa fa-check"></i><b>9.13</b> Radial Kernels, cont.<span></span></a></li>
<li class="chapter" data-level="9.14" data-path="svms-with-more-than-two-classes.html"><a href="svms-with-more-than-two-classes.html"><i class="fa fa-check"></i><b>9.14</b> SVMs with More than Two Classes<span></span></a></li>
<li class="chapter" data-level="9.15" data-path="lab-support-vector-classifier.html"><a href="lab-support-vector-classifier.html"><i class="fa fa-check"></i><b>9.15</b> Lab: Support Vector Classifier<span></span></a><ul>
<li class="chapter" data-level="9.15.1" data-path="lab-support-vector-classifier.html"><a href="lab-support-vector-classifier.html#tuning"><i class="fa fa-check"></i><b>9.15.1</b> Tuning<span></span></a></li>
<li class="chapter" data-level="9.15.2" data-path="lab-support-vector-classifier.html"><a href="lab-support-vector-classifier.html#linearly-separable-data"><i class="fa fa-check"></i><b>9.15.2</b> Linearly separable data<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.16" data-path="lab-support-vector-machine-non-linear-kernel.html"><a href="lab-support-vector-machine-non-linear-kernel.html"><i class="fa fa-check"></i><b>9.16</b> Lab: Support Vector Machine (non-linear kernel)<span></span></a></li>
<li class="chapter" data-level="9.17" data-path="meeting-videos-8.html"><a href="meeting-videos-8.html"><i class="fa fa-check"></i><b>9.17</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="9.17.1" data-path="meeting-videos-8.html"><a href="meeting-videos-8.html#cohort-1-8"><i class="fa fa-check"></i><b>9.17.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="9.17.2" data-path="meeting-videos-8.html"><a href="meeting-videos-8.html#cohort-2-8"><i class="fa fa-check"></i><b>9.17.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="9.17.3" data-path="meeting-videos-8.html"><a href="meeting-videos-8.html#cohort-3-8"><i class="fa fa-check"></i><b>9.17.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>10</b> Deep Learning<span></span></a><ul>
<li class="chapter" data-level="10.1" data-path="slide-1-1.html"><a href="slide-1-1.html"><i class="fa fa-check"></i><b>10.1</b> Slide 1<span></span></a></li>
<li class="chapter" data-level="10.2" data-path="slide-2-1.html"><a href="slide-2-1.html"><i class="fa fa-check"></i><b>10.2</b> Slide 2<span></span></a></li>
<li class="chapter" data-level="10.3" data-path="meeting-videos-9.html"><a href="meeting-videos-9.html"><i class="fa fa-check"></i><b>10.3</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="10.3.1" data-path="meeting-videos-9.html"><a href="meeting-videos-9.html#cohort-1-9"><i class="fa fa-check"></i><b>10.3.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="10.3.2" data-path="meeting-videos-9.html"><a href="meeting-videos-9.html#cohort-2-9"><i class="fa fa-check"></i><b>10.3.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="10.3.3" data-path="meeting-videos-9.html"><a href="meeting-videos-9.html#cohort-3-9"><i class="fa fa-check"></i><b>10.3.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html"><i class="fa fa-check"></i><b>11</b> Survival Analysis and Censored Data<span></span></a><ul>
<li class="chapter" data-level="11.1" data-path="slide-1-2.html"><a href="slide-1-2.html"><i class="fa fa-check"></i><b>11.1</b> Slide 1<span></span></a></li>
<li class="chapter" data-level="11.2" data-path="slide-2-2.html"><a href="slide-2-2.html"><i class="fa fa-check"></i><b>11.2</b> Slide 2<span></span></a></li>
<li class="chapter" data-level="11.3" data-path="meeting-videos-10.html"><a href="meeting-videos-10.html"><i class="fa fa-check"></i><b>11.3</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="11.3.1" data-path="meeting-videos-10.html"><a href="meeting-videos-10.html#cohort-1-10"><i class="fa fa-check"></i><b>11.3.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="11.3.2" data-path="meeting-videos-10.html"><a href="meeting-videos-10.html#cohort-2-10"><i class="fa fa-check"></i><b>11.3.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="11.3.3" data-path="meeting-videos-10.html"><a href="meeting-videos-10.html#cohort-3-10"><i class="fa fa-check"></i><b>11.3.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html"><i class="fa fa-check"></i><b>12</b> Unsupervised Learning<span></span></a><ul>
<li class="chapter" data-level="12.1" data-path="slide-1-3.html"><a href="slide-1-3.html"><i class="fa fa-check"></i><b>12.1</b> Slide 1<span></span></a></li>
<li class="chapter" data-level="12.2" data-path="slide-2-3.html"><a href="slide-2-3.html"><i class="fa fa-check"></i><b>12.2</b> Slide 2<span></span></a></li>
<li class="chapter" data-level="12.3" data-path="meeting-videos-11.html"><a href="meeting-videos-11.html"><i class="fa fa-check"></i><b>12.3</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="12.3.1" data-path="meeting-videos-11.html"><a href="meeting-videos-11.html#cohort-1-11"><i class="fa fa-check"></i><b>12.3.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="12.3.2" data-path="meeting-videos-11.html"><a href="meeting-videos-11.html#cohort-2-11"><i class="fa fa-check"></i><b>12.3.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="12.3.3" data-path="meeting-videos-11.html"><a href="meeting-videos-11.html#cohort-3-11"><i class="fa fa-check"></i><b>12.3.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="multiple-testing.html"><a href="multiple-testing.html"><i class="fa fa-check"></i><b>13</b> Multiple Testing<span></span></a><ul>
<li class="chapter" data-level="13.1" data-path="slide-1-4.html"><a href="slide-1-4.html"><i class="fa fa-check"></i><b>13.1</b> Slide 1<span></span></a></li>
<li class="chapter" data-level="13.2" data-path="slide-2-4.html"><a href="slide-2-4.html"><i class="fa fa-check"></i><b>13.2</b> Slide 2<span></span></a></li>
<li class="chapter" data-level="13.3" data-path="meeting-videos-12.html"><a href="meeting-videos-12.html"><i class="fa fa-check"></i><b>13.3</b> Meeting Videos<span></span></a><ul>
<li class="chapter" data-level="13.3.1" data-path="meeting-videos-12.html"><a href="meeting-videos-12.html#cohort-1-12"><i class="fa fa-check"></i><b>13.3.1</b> Cohort 1<span></span></a></li>
<li class="chapter" data-level="13.3.2" data-path="meeting-videos-12.html"><a href="meeting-videos-12.html#cohort-2-12"><i class="fa fa-check"></i><b>13.3.2</b> Cohort 2<span></span></a></li>
<li class="chapter" data-level="13.3.3" data-path="meeting-videos-12.html"><a href="meeting-videos-12.html#cohort-3-12"><i class="fa fa-check"></i><b>13.3.3</b> Cohort 3<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="abbreviations.html#abbreviations">Abbreviations<span></span></a></li>
<li><a href="latex.html#latex">Appendix: Bookdown and LaTeX Notes<span></span></a><ul>
<li><a href="markdown-highlighting.html#markdown-highlighting">Markdown highlighting<span></span></a></li>
<li><a href="text-coloring.html#text-coloring">Text coloring<span></span></a></li>
<li><a href="x99-4.html#x99-4">Section references<span></span></a></li>
<li><a href="footnotes.html#footnotes">Footnotes<span></span></a></li>
<li><a href="formatting-text.html#formatting-text">Formatting Text<span></span></a></li>
<li><a href="figures.html#figures">Figures<span></span></a></li>
<li><a href="displaying-formula.html#displaying-formula">Displaying Formula<span></span></a><ul>
<li><a href="displaying-formula.html#formatting">Formatting<span></span></a></li>
<li><a href="displaying-formula.html#symbols">Symbols<span></span></a></li>
<li><a href="displaying-formula.html#notation-1">Notation<span></span></a></li>
</ul></li>
<li><a href="equations.html#equations">Equations<span></span></a><ul>
<li><a href="equations.html#basic-equation">Basic Equation<span></span></a></li>
<li><a href="equations.html#case-when-equation-large-curly-brace">Case-When Equation (Large Curly Brace)<span></span></a></li>
<li><a href="equations.html#alligned-with-underbars">Alligned with Underbars<span></span></a></li>
</ul></li>
<li><a href="greek-letters.html#greek-letters">Greek letters<span></span></a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Statistical Learning Using R Book Club</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="meeting-videos-1" class="section level2 hasAnchor">
<h2><span class="header-section-number">2.4</span> Meeting Videos<a href="meeting-videos-1.html#meeting-videos-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="cohort-1-1" class="section level3 hasAnchor">
<h3><span class="header-section-number">2.4.1</span> Cohort 1<a href="meeting-videos-1.html#cohort-1-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<iframe src="https://www.youtube.com/embed/P8BMLBplcTE" width="100%" height="400px" data-external="1">
</iframe>
<details>
<p><summary> Meeting chat log 1</summary></p>
<pre><code>00:08:32    Fran Barton:    A very rainy afternoon here in this corner of England
00:09:17    Kim Martin: Good afternoon everyone :)
00:09:31    Stijn:  Hiya!
00:09:59    Jon Harmon (jonthegeek):    Good {time wherever you are}, everyone!
00:11:49    Stijn:  You type like a programmer would, Jon
00:13:10    Kim Martin: @Stijn How does a programmer type?
00:13:24    Kim Martin: The curly braces?
00:13:51    Stijn:  Hahaha, just making lame jokes over here. Let&#39;s not read into it too much :D
00:14:04    Kim Martin: (overthinking-R-us)
00:14:09    shamsuddeen:    Increase the size pls
00:14:49    Wayne Defreitas:    if you go to view options in zoom, you can also zoom screen size
00:15:38    Fran Barton:    Would it be possible to F11 to make the browser full screen?
00:15:48    Kim Martin: These are your _notes_?!
00:15:49    August: That is awesome, thank you!
00:15:54    shamsuddeen:    Thanks
00:15:55    Stijn:  That is REALLY cool, thanks Ray!
00:16:00    Kim Martin: Link please!
00:16:09    Mei Ling Soh:   Loved the appendix section
00:16:10    Laura Rose: very cool; thanks!
00:16:11    Keuntae Kim:    awesome!!! I need this!!!
00:16:22    Ryan Metcalf:   This is great. Thank you!
00:16:30    Kim Martin: Ah - found it: https://r4ds.github.io/bookclub-islr/statistical-learning.html
00:16:43    Jon Harmon (jonthegeek):    r4ds.io/islr is the shortcut
00:17:28    Stijn:  dependent and independent variables is what I&#39;m used to
00:17:44    Fran Barton:    I&#39;m pretty new to all of this so I&#39;ll just take whatever terminology I&#39;m given for now
00:17:52    Jon Harmon (jonthegeek):    Note to self: I should increase the default font size in this notes-book.
00:18:23    Brett Longworth:    Features is newish to me. Not part of the ML club. =)
00:20:19    Jon Harmon (jonthegeek):    &quot;Features&quot; is more used in the ML world, &quot;independent variable&quot; in actual science, in my experience.
00:21:12    Jyoti:  the estimates of the regression coefficients are computed such that on an average the estimate of error becomes zero
00:21:30    Jon Harmon (jonthegeek):    There&#39;s always a (somewhat) relevant xkcd: https://xkcd.com/2048/
00:22:18    Till:   from a probabilistic point, given that you model is correct, the error distribution is assumed to have a zero mean and any deviations from a prediction is completely random
00:23:31    Fran Barton:    &quot;the whole point of the book is to present different ways to come up with surfaces like this&quot; (or something like that - Ray) - thank you, I like that kind of context, helps me get the bigger picture.
00:23:37    shamsuddeen:    Y is also a function of ϵ, which, by definition, cannot be predicted using X. What this means from the book?
00:24:18    Kim Martin: Y = f(X)  if everything about Y can be (perfectly) predicted by X
00:24:44    Jon Harmon (jonthegeek):    Y depends on both X and epsilon, and you can&#39;t predict epsilon from X; if you could, it&#39;d be part of f(X).
00:25:04    Kim Martin: … but since Y _cannot_ be perfectly predicted just with X (there are other important variables that are not included in X... or some unpredictable randomness) this is acknowledged by adding the error term... hence Y = f(X) + e
00:26:43    shamsuddeen:    It is important to keep in mind that the irreducible error will always provide an upper bound on the accuracy of our prediction for Y. This bound is almost always unknown in practice.
00:28:20    shamsuddeen:    Thank you
00:29:52    August: this is basically image 2.9
00:30:52    Kim Martin: Every point in the _training_ set... but what about the _test_ set?
00:31:20    Kim Martin: You can fit your function perfect... with no errors... to your training set... but what happens when you get new data?
00:31:35    Rahul T:    I think here it’s on the whole population but in most cases we only have sample and we can fit that sample well but doesn’t mean it will generalize well to the population
00:31:36    shamsuddeen:    Uhmmm
00:31:39    shamsuddeen:    Thanks
00:33:25    SriRam: In complex theory, you may call this rationality vs bounded rationality , there is always a boundary stopping you from knowing everything
00:33:28    shamsuddeen:    I got it. Rahu, your point also make sense.
00:33:36    Brett Longworth:    We can fit a function that fits all points, but that removes irreducible error, which I think is the definition of overfitting?
00:33:54    shamsuddeen:    Yes, Bret I guess so
00:34:47    Brett Longworth:    Best argument for a training and test set I&#39;ve heard. Overfitting should show up in the fit for the test set.
00:35:02    Kim Martin: Some domains have smaller error than others though... e.g. simple physics experiments will have a smaller error than (eg) experiments involving complex systems (including human behaviour)
00:35:16    Keuntae Kim:    Also, the perfect prediction model for the sample does not necessarily guarantee prefect predicted outcomes when a new dataset comes into the model.
00:36:06    Fran Barton:    I wonder if there is some confusion among the group as to the meaning of the word &quot;error&quot;. Here it doesn&#39;t mean that you as a researcher have done something wrong. It doesn&#39;t mean the model is unusable. It just means any useful model will inevitably only approximate to the phenomenon itself.
00:36:20    Sangeeta Bhatia:    yes that makes sense. if we knew the truth, we won’t need “f”.
00:36:47    Brett Longworth:    So for the physics example, running a jagged line through all points of a distance vs time curve would immediately be shown to be an overfit when predicting with new data.
00:37:50    Kim Martin: That&#39;s whey section 2.2.1 goes to pains to emphasize that the model should be assessed (MSE etc) based on the test data, not the training set (which will most likely be far lower)
00:38:16    August: I think we are getting overly bogged down here, this is revisited several times as the book progresses
00:38:28    shamsuddeen:    Yes, lets progress
00:45:06    shamsuddeen:    How to make this kind of plot in ggplot?
00:45:52    Keuntae Kim:    geom_contour() &lt;- I guess
00:46:02    Stijn:  https://www.r-graph-gallery.com/3d-surface-plot.html
00:46:10    Stijn:  Not ggplot though
00:46:22    Keuntae Kim:    https://ggplot2.tidyverse.org/reference/geom_contour.html#:~:text=ggplot2%20can%20not%20draw%20true,can%20appear%20at%20most%20once.
00:46:25    August: https://stackoverflow.com/questions/38331198/add-regression-plane-to-3d-scatter-plot-in-plotly
00:46:32    Keuntae Kim:    Okay..
00:46:34    August: plotly for the win
00:46:36    Ryan Metcalf:   Ive tried this 3D in Python. (But that doesn’t apply to R.)
00:47:10    Stijn:  And let&#39;s give rayshader an honourable mention for 3D stuff!
00:48:09    Rahul T:    I am not sure if this has the code - it’s listed on the book site as a resource https://web.stanford.edu/~hastie/ISLR2/Labs/
00:49:06    Jon Harmon (jonthegeek):    A long, unfinished thread about surface in R: https://rfordatascience.slack.com/archives/C8JRJSW4S/p1627573385008700
00:49:54    Jon Harmon (jonthegeek):    @rahul That&#39;s just the labs (~1/2 of each chapter).
00:51:35    Rahul T:    Got it, thanks!
00:51:38    Kim Martin: Super cynical, Raymond 😂
00:52:02    August: Hey that&#39;s my job your talking about! :P
00:52:10    Ryan S: I&#39;m going to try that approach with my boss -- &quot;I need more money because I can do better!&quot;
00:52:18    Kim Martin: Why MSE vs RMSE?
00:52:21    August: but I can!
00:52:45    Kim Martin: Only to get units in normal sense?
00:53:28    Rahul T:    May be it’s easy to derive the bias variance tradeoff - just a guess
00:53:30    Kim Martin: Why does ISLR2 stop at MSE? Because it does the job (getting &#39;normal units&#39; is irrelevant)?
00:53:31    shamsuddeen:    No Free Lunch Theorem for Machine Learning: https://machinelearningmastery.com/no-free-lunch-theorem-for-machine-learning/
00:54:29    Jon Harmon (jonthegeek):    Yeah, that&#39;d be my take. RMSE is usually more reportable but if you&#39;re just trying to calculate a number to compare your fit to another fit. I definitely prefer RMSE!
00:55:34    Stijn:  I&#39;m not sure what the &#39;decrease-stagnate-increase&#39; implies :/
00:57:37    Stijn:  Whew, I think it&#39;s somewhat clicking... Will have to re-read
00:58:43    Keuntae Kim:    In the figure at the top, a yellow linear line is too simple, so a lot of errors when a new dataset comes in, so weak predictive power.
00:59:16    Kim Martin: How are they quantifying &#39;flexibility&#39;?
00:59:43    Kim Martin: Number of parameters to estimate (2 for linear)?
00:59:51    Rahul T:    Book says “degrees of freedom, for a number of smoothing splines.”
01:00:07    Rahul T:    It will be discussed in ch7
01:00:10    Keuntae Kim:    For the line passing through every point, no errors (almost zero variance), but extremely hard to predict or estimate values when a new dataset comes in.
01:00:22    Keuntae Kim:    This is what I understand from the figures.
01:00:25    Rahul T:    They say at the end of page 31
01:04:20    David Severski: We’re coming up on time, do we want to find a good point to pause until next week?
01:04:43    Stijn:  The idea that a biostats college professor also finds some of these sections challenging, makes me feel much more comfortable 😅
01:05:12    Kim Martin: 😅👍
01:05:38    Mei Ling Soh:   I think we should stop at the bias-variance trade-off
01:07:46    shamsuddeen:    Dev set
01:09:23    August: p36 explains this
01:09:59    David Severski: I’ve got to jet. Thanks for presenting and to everyone for the discussion!
01:10:42    Kim Martin: Is the aim to do the lab next week, or the week after?
01:10:49    Keuntae Kim:    Good session today. Too many confusing things I have to digest!!! Need to study of my own more!!! haha 😅
01:11:16    Kim Martin: (I&#39;ll confess I didn&#39;t get through the Chapter, despite intending to have read it all by today)
01:11:31    Keuntae Kim:    Ray, thank you very much. You did a great job to explain these complex things!
01:11:34    Mei Ling Soh:   So, we have to try out the exercises before the next study session?
01:11:46    shamsuddeen:    Thank you Ray.
01:11:50    August: try the lectures online if you struggle with the book, it&#39;ll help reading the material.
01:11:53    Kim Martin: It might be nice to try to share code / visuals for (trying to) explore these topics more
01:12:01    Mei Ling Soh:   Thank you, Ray!
01:12:08    Laura Rose: Thanks, Ray!
01:12:09    collinberke:    Thanks, Ray!
01:12:17    Rahul T:    This was very helpful. Thank you, Ray!
01:12:26    Till:   yes, many thanks!
01:12:31    Kaustav Sen:    Thanks Ray!  
01:12:51    Kim Martin: @August you mean these: https://www.dataschool.io/15-hours-of-expert-machine-learning-videos/
01:13:09    August: https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/statistical-learning.html
01:13:37    Fran Barton:    thanks everyone
01:14:10    Ryan S: Thanks everyone!
01:14:14    Kim Martin: Thanks all!
01:14:16    Keuntae Kim:    Thank you everyone!</code></pre>
</details>
<iframe src="https://www.youtube.com/embed/MfBUPmK-aNg" width="100%" height="400px" data-external="1">
</iframe>
<details>
<p><summary> Meeting chat log 2</summary></p>
<pre><code>00:05:01    A. S. Ghatpande:    Hello
00:05:35    jonathan.bratt: hello!
00:07:02    Ryan Metcalf:   Good morning/afternoon/evening everyone!
00:08:02    jonathan.bratt: I missed last week; Ray, were you going to finish going through chapter 2 today?
00:09:41    David Severski: I just noticed Raymond’s Skinny Puppy poster. Awesome. Now I need to queue that up for today.
00:09:45    David Severski: 😄
00:12:11    Ryan Metcalf:   Ryan S.
00:19:33    A. S. Ghatpande:    How would you calculate bias in the example given?
00:19:48    Jon Harmon (jonthegeek):    r4ds.io/islr
00:22:40    shamsuddeen:    We do have validation test also sometimes. Is that called validation error ?
00:24:00    shamsuddeen:    The chapter seems not discuss anything about validation set
00:25:14    SriRam: K is number of neighbors to consider I think
00:27:29    Rahul T:    I think it’s (f - E(f_hat))
00:28:11    Rahul T:    f is true function and E(f_hat) in different samples expected value
00:29:03    SriRam: Bias is error predicted vs observed , from my understanding
00:29:29    August: might be useful: http://scott.fortmann-roe.com/docs/BiasVariance.html
00:30:12    Keuntae Kim:    https://www.value-at-risk.net/bias/ &lt;-- about bias in a mathematical way, but it is basically about the difference between the actual and estimated values.
00:31:33    A. S. Ghatpande:    thanks for all the answers here about bias, enough food for thought
00:37:52    Ryan Metcalf:   Would you be able to wrangle the data or clean the data more?
00:38:01    Ryan Metcalf:   If it is noise, likely not.
00:38:12    A. S. Ghatpande:    you need more data!
00:38:33    August: Yes and not depends on data and what you can bring in i.e weather data or create from the data ie pca
00:53:53    Rahul T:    Got it, that’s helpful. Thank you!
00:56:43    August: basically predictive power is desirable, but not the main concern with inferential. Sometime you have to sacrifice predictive accuracy for explainability. Generally you hope to approach consensus within the zeitgeist.
00:57:01    shamsuddeen:    Email spam classification
01:03:05    A. S. Ghatpande:    spammers wrote inferential models!
01:03:14    SriRam: Lol
01:04:58    Raymond Balise: so sorry I need to be in another meeting in two minutes
01:05:23    Jon Harmon (jonthegeek):    No problem, we&#39;ll stop very soon.
01:06:06    shamsuddeen:    I need to leave now. See u all next. Thanks
01:06:46    Rahul T:    Thank you!
01:06:50    A. S. Ghatpande:    very good thankseveryone
01:06:51    collinberke:    Thank you!
01:06:52    Ryan S: thanks!</code></pre>
</details>
</div>
<div id="cohort-2-1" class="section level3 hasAnchor">
<h3><span class="header-section-number">2.4.2</span> Cohort 2<a href="meeting-videos-1.html#cohort-2-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<iframe src="https://www.youtube.com/embed/FpynCQNFIXs" width="100%" height="400px" data-external="1">
</iframe>
<details>
<p><summary> Meeting chat log </summary></p>
<pre><code>00:22:35    Ricardo Serrano:    Simpson’s Paradox is a statistical phenomenon where an association between two variables in a population emerges, disappears or reverses when the population is divided into subpopulations. https://plato.stanford.edu/entries/paradox-simpson/
00:28:46    Michael Haugen: the book defines irreducible error as measurement errors and/or unmeasured variables.
00:33:45    Michael Haugen: Interesting that baseball has the concept of “unforced error.”To create error due to not having the best functional form (reducible error) is kind of like an unforced error.
00:42:27    Ricardo Serrano:    NLP is another unsupervised learning methodology
00:48:50    Michael Haugen: the green line is a good example of being too wiggly right?
01:01:16    Federica Gazzelloni:    Dimensionality reduction: https://juliasilge.com/blog/billboard-100/
01:02:05    Michael Haugen: Online version of book: http://www.feat.engineering/
01:03:59    Michael Haugen: one stats book to another</code></pre>
</details>
<iframe src="https://www.youtube.com/embed/9YTfQO38XCk" width="100%" height="400px" data-external="1">
</iframe>
<details>
<p><summary> Meeting chat log </summary></p>
<pre><code>00:54:05    Ricardo:    MNIST dataset</code></pre>
</details>
</div>
<div id="cohort-3-1" class="section level3 hasAnchor">
<h3><span class="header-section-number">2.4.3</span> Cohort 3<a href="meeting-videos-1.html#cohort-3-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<iframe src="https://www.youtube.com/embed/fxq7hbLyv7c" width="100%" height="400px" data-external="1">
</iframe>
<details>
<p><summary> Meeting chat log </summary></p>
<pre><code>00:09:52    Fariborz Soroush:   none here :)
00:31:06    Mei Ling Soh:   More on parametric and non-parametric tests: https://byjus.com/maths/difference-between-parametric-and-nonparametric/#:~:text=The%20key%20difference%20between%20parametric,tendency%20with%20the%20median%20value.
00:31:28    Mei Ling Soh:   Sometimes, it is better to use non-parametric tests as they are based on median
00:35:15    Mei Ling Soh:   ggplot-2 book: https://ggplot2-book.org/
00:36:06    Mei Ling Soh:   Bookclub on slack `#book_club-ggplot2`
00:39:58    Jeremy Selva:   Welch t test is not equal variance one. Student is the equal variance one. Both are parametric because they assume a normal (known) distribution.
00:41:43    Mei Ling Soh:   Thanks, Jeremy. I thought welch was a non-parametric test 😅
00:54:26    Rahul:  This is my derivation for the earlier equation we were talking about.
01:05:56    Rahul:  This has a good info on parametric vs non parametric https://sebastianraschka.com/faq/docs/parametric_vs_nonparametric.html
01:06:03    Rahul:  For later read
01:06:07    Rahul:  Thank you!</code></pre>
</details>
<iframe src="https://www.youtube.com/embed/T1C-YMdP2ZU" width="100%" height="400px" data-external="1">
</iframe>
<details>
<p><summary> Meeting chat log </summary></p>
<pre><code>00:27:35    Mei Ling Soh:   https://www.crumplab.com/statisticsLab/lab-10-factorial-anova.html
00:28:41    Mei Ling Soh:   The answers👆
00:31:51    Rose Franzen:   Sorry Mei Ling, the answers for what? That link doesn’t seem to be related to this content (unless I’m totally missing something, which is possible 🙂 )
00:32:44    Mei Ling Soh:   https://onmee.github.io/assets/docs/ISLR/Statistical-Learning.pdf
00:55:06    Rose Hartman:   My preference is to rush through so we can keep getting to new content 🙂
00:55:11    Celine H:   I’d rather take our time to go through the material
00:55:13    shamsuddeen:    Where is the sign-up sheet?
00:55:25    Nilay Yönet:    https://docs.google.com/spreadsheets/d/1xab0RUdnUC6V-RkXvZqTcLvJrkY6T2ZHAZSUDA_krn4/edit#gid=0
00:55:30    Celine H:   I’m ok either way.
00:55:39    Rose Hartman:   Me too 🙂
00:57:59    Celine H:   I’d love to see the tidy model example.
00:58:06    Celine H:   tidyverse</code></pre>
</details>

</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="exercises.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linear.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/r4ds/bookclub-islr/edit/main/02.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
